{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Titanic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Predict Survival of passengers on the Titanic\n",
    "Reference: https://ww2.amstat.org/publications/jse/v3n3/datasets.dawson.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Machine Learning Library of PySpark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.sql import Row, SQLContext\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Library for confusion matrix, precision, test error\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "# Library For Area under ROC curve and Area under precision-recall curve\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "# Assign resources to the application\n",
    "sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The data will be loaded into an array.\n",
    "This is the summary of the data structure, including the column position and name.\n",
    "The first filed starts from position 0. \n",
    "\n",
    "0 Name    -  Passenger first and last name.\n",
    "\n",
    "1 PClass  -  Passenger class (1st, 2nd, or 3rd)\n",
    "\n",
    "2 Age\n",
    "\n",
    "3 Sex\n",
    "\n",
    "4 Survived -  1 if the passenger survived;  0 if the passenger did not survive\n",
    "\n",
    "5 PersonID\n",
    "\n",
    "Label is a target variable.  PersonInfo is a list of independent variables besides unique identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the titanic csv file into a spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name=u'Allen Miss Elisabeth Walton', PClass=u'1st', Age=u'29', Sex=u'female', Survived=u'1', PersonID=u'1'),\n",
       " Row(Name=u'Allison Miss Helen Loraine', PClass=u'1st', Age=u'2', Sex=u'female', Survived=u'0', PersonID=u'2'),\n",
       " Row(Name=u'Allison Mr Hudson Joshua Creighton', PClass=u'1st', Age=u'30', Sex=u'male', Survived=u'0', PersonID=u'3'),\n",
       " Row(Name=u'Allison Mrs Hudson JC (Bessie Waldo Daniels)', PClass=u'1st', Age=u'25', Sex=u'female', Survived=u'0', PersonID=u'4'),\n",
       " Row(Name=u'Allison Master Hudson Trevor', PClass=u'1st', Age=u'0.92', Sex=u'male', Survived=u'1', PersonID=u'5')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import ibmos2spark\n",
    "\n",
    "# @hidden_cell\n",
    "credentials = {\n",
    "    'auth_url': 'https://identity.open.softlayer.com',\n",
    "    'project_id': '7984a968f14449858d826f8ba838fbb3',\n",
    "    'region': 'dallas',\n",
    "    'user_id': '51e14119a08842f0a9311ea21a5debfc',\n",
    "    'username': 'member_c8a299d593b1d03a3e131a4df7aec8a60c5f34ce',\n",
    "    'password': 'DWy^2pn8K=WMrUIu'\n",
    "}\n",
    "\n",
    "configuration_name = 'os_85a89ae392d2473988f606b7870013f9_configs'\n",
    "bmos = ibmos2spark.bluemix(sc, credentials, configuration_name)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df_data_2 = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option('header', 'true')\\\n",
    "  .load(bmos.url('DefaultProjectagarner18studentumucedu', 'Titanic.csv'))\n",
    "df_data_2.take(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data frame schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- PClass: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- PersonID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+----+------+--------+--------+-----------+--------+\n",
      "|                Name|PClass| Age|   Sex|Survived|PersonID|PClassIndex|SexIndex|\n",
      "+--------------------+------+----+------+--------+--------+-----------+--------+\n",
      "|Allen Miss Elisab...|   1st|  29|female|       1|       1|        1.0|     1.0|\n",
      "|Allison Miss Hele...|   1st|   2|female|       0|       2|        1.0|     1.0|\n",
      "|Allison Mr Hudson...|   1st|  30|  male|       0|       3|        1.0|     0.0|\n",
      "|Allison Mrs Hudso...|   1st|  25|female|       0|       4|        1.0|     1.0|\n",
      "|Allison Master Hu...|   1st|0.92|  male|       1|       5|        1.0|     0.0|\n",
      "|   Anderson Mr Harry|   1st|  47|  male|       1|       6|        1.0|     0.0|\n",
      "|Andrews Miss Korn...|   1st|  63|female|       1|       7|        1.0|     1.0|\n",
      "|Andrews Mr Thomas jr|   1st|  39|  male|       0|       8|        1.0|     0.0|\n",
      "|Appleton Mrs Edwa...|   1st|  58|female|       1|       9|        1.0|     1.0|\n",
      "|Artagaveytia Mr R...|   1st|  71|  male|       0|      10|        1.0|     0.0|\n",
      "|Astor Colonel Joh...|   1st|  47|  male|       0|      11|        1.0|     0.0|\n",
      "|Astor Mrs John Ja...|   1st|  19|female|       1|      12|        1.0|     1.0|\n",
      "|Baxter Mrs James ...|   1st|  50|female|       1|      13|        1.0|     1.0|\n",
      "|Baxter Mr Quigg E...|   1st|  24|  male|       0|      14|        1.0|     0.0|\n",
      "|  Beattie Mr Thomson|   1st|  36|  male|       0|      15|        1.0|     0.0|\n",
      "|Beckwith Mr Richa...|   1st|  37|  male|       1|      16|        1.0|     0.0|\n",
      "|Beckwith Mrs Rich...|   1st|  47|female|       1|      17|        1.0|     1.0|\n",
      "| Behr Mr Karl Howell|   1st|  26|  male|       1|      18|        1.0|     0.0|\n",
      "|   Birnbaum Mr Jakob|   1st|  25|  male|       0|      19|        1.0|     0.0|\n",
      "|Bishop Mr Dickins...|   1st|  25|  male|       1|      20|        1.0|     0.0|\n",
      "+--------------------+------+----+------+--------+--------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer_PClass = StringIndexer(inputCol=\"PClass\", outputCol=\"PClassIndex\")\n",
    "indexed = indexer_PClass.fit(df_data_2).transform(df_data_2)\n",
    "indexer_Sex = StringIndexer(inputCol=\"Sex\", outputCol=\"SexIndex\")\n",
    "indexed_2 = indexer_Sex.fit(indexed).transform(indexed)\n",
    "indexed_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = indexed_2['PClassIndex', 'Age', 'SexIndex', 'Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+--------+--------+\n",
      "|PClassIndex| Age|SexIndex|Survived|\n",
      "+-----------+----+--------+--------+\n",
      "|        1.0|  29|     1.0|       1|\n",
      "|        1.0|   2|     1.0|       0|\n",
      "|        1.0|  30|     0.0|       0|\n",
      "|        1.0|  25|     1.0|       0|\n",
      "|        1.0|0.92|     0.0|       1|\n",
      "|        1.0|  47|     0.0|       1|\n",
      "|        1.0|  63|     1.0|       1|\n",
      "|        1.0|  39|     0.0|       0|\n",
      "|        1.0|  58|     1.0|       1|\n",
      "|        1.0|  71|     0.0|       0|\n",
      "|        1.0|  47|     0.0|       0|\n",
      "|        1.0|  19|     1.0|       1|\n",
      "|        1.0|  50|     1.0|       1|\n",
      "|        1.0|  24|     0.0|       0|\n",
      "|        1.0|  36|     0.0|       0|\n",
      "|        1.0|  37|     0.0|       1|\n",
      "|        1.0|  47|     1.0|       1|\n",
      "|        1.0|  26|     0.0|       1|\n",
      "|        1.0|  25|     0.0|       0|\n",
      "|        1.0|  25|     0.0|       1|\n",
      "+-----------+----+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert from string to double type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col  # for indicating a column using a string in the line below\n",
    "data = data.select([col(c).cast(\"double\").alias(c) for c in data.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate that the type is double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PClassIndex: double (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SexIndex: double (nullable = true)\n",
      " |-- Survived: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find correlations between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with age:\n",
      "survived: -0.0612539137238\n",
      "sex: -0.0551378307708\n",
      "pclass: 0.135561650597\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "age_survived=data.stat.corr('Age', 'Survived')\n",
    "age_sex=data.stat.corr('Age', 'SexIndex')\n",
    "age_pclass=data.stat.corr('Age', 'PClassIndex')\n",
    "\n",
    "print(\"Correlation with age:\")\n",
    "print(\"survived: \"+ str(age_survived))\n",
    "print(\"sex: \"+ str(age_sex))\n",
    "print(\"pclass: \"+ str(age_pclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with sex:\n",
      "survived: 0.540627642826\n",
      "age: -0.0551378307708\n",
      "pclass: 0.077151133994\n"
     ]
    }
   ],
   "source": [
    "sex_survived=data.stat.corr('SexIndex', 'Survived')\n",
    "sex_age=data.stat.corr('SexIndex', 'Age')\n",
    "sex_pclass=data.stat.corr('SexIndex', 'PClassIndex')\n",
    "\n",
    "print(\"Correlation with sex:\")\n",
    "print(\"survived: \"+ str(sex_survived))\n",
    "print(\"age: \"+ str(sex_age))\n",
    "print(\"pclass: \"+ str(sex_pclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with pclass:\n",
      "survived: 0.201335044942\n",
      "age: 0.135561650597\n",
      "sex: 0.077151133994\n"
     ]
    }
   ],
   "source": [
    "pclass_survived=data.stat.corr('PClassIndex', 'Survived')\n",
    "pclass_age=data.stat.corr('PClassIndex', 'Age')\n",
    "pclass_sex=data.stat.corr('PClassIndex', 'SexIndex')\n",
    "\n",
    "print(\"Correlation with pclass:\")\n",
    "print(\"survived: \"+ str(pclass_survived))\n",
    "print(\"age: \"+ str(pclass_age))\n",
    "print(\"sex: \"+ str(pclass_sex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  # Split the data into training and test sets (20% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.95, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the spark dataframe into a labeledpoint rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingData  = trainingData.rdd.map(lambda x: LabeledPoint(x[3], x[0:2]))\n",
    "testData = testData.rdd.map(lambda x: LabeledPoint(x[3], x[0:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a decision tree model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train a DecisionTree model.\n",
    "#  Empty categoricalFeaturesInfo indicates all features are continuous.\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "model = DecisionTree.trainClassifier(trainingData, numClasses=2, categoricalFeaturesInfo={},impurity='gini', maxDepth=10, maxBins=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get accuracy measures for the decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error = 0.247035573123\n",
      "Training Accuracy = 0.752964426877\n",
      "Learned classification random forest model:\n",
      "DecisionTreeModel classifier of depth 10 with 119 nodes\n",
      "  If (feature 0 <= 0.0)\n",
      "   If (feature 1 <= 7.0)\n",
      "    If (feature 1 <= 2.0)\n",
      "     Predict: 1.0\n",
      "    Else (feature 1 > 2.0)\n",
      "     Predict: 1.0\n",
      "   Else (feature 1 > 7.0)\n",
      "    If (feature 1 <= 60.0)\n",
      "     If (feature 1 <= 23.0)\n",
      "      If (feature 1 <= 13.0)\n",
      "       Predict: 0.0\n",
      "      Else (feature 1 > 13.0)\n",
      "       If (feature 1 <= 18.0)\n",
      "        If (feature 1 <= 17.0)\n",
      "         Predict: 0.0\n",
      "        Else (feature 1 > 17.0)\n",
      "         Predict: 0.0\n",
      "       Else (feature 1 > 18.0)\n",
      "        If (feature 1 <= 21.0)\n",
      "         If (feature 1 <= 19.0)\n",
      "          Predict: 0.0\n",
      "         Else (feature 1 > 19.0)\n",
      "          If (feature 1 <= 20.0)\n",
      "           Predict: 0.0\n",
      "          Else (feature 1 > 20.0)\n",
      "           Predict: 0.0\n",
      "        Else (feature 1 > 21.0)\n",
      "         If (feature 1 <= 22.0)\n",
      "          Predict: 0.0\n",
      "         Else (feature 1 > 22.0)\n",
      "          Predict: 0.0\n",
      "     Else (feature 1 > 23.0)\n",
      "      If (feature 1 <= 45.0)\n",
      "       If (feature 1 <= 44.0)\n",
      "        If (feature 1 <= 39.0)\n",
      "         If (feature 1 <= 29.0)\n",
      "          If (feature 1 <= 27.0)\n",
      "           If (feature 1 <= 25.0)\n",
      "            Predict: 0.0\n",
      "           Else (feature 1 > 25.0)\n",
      "            Predict: 0.0\n",
      "          Else (feature 1 > 27.0)\n",
      "           Predict: 0.0\n",
      "         Else (feature 1 > 29.0)\n",
      "          If (feature 1 <= 32.0)\n",
      "           If (feature 1 <= 31.0)\n",
      "            Predict: 0.0\n",
      "           Else (feature 1 > 31.0)\n",
      "            Predict: 0.0\n",
      "          Else (feature 1 > 32.0)\n",
      "           If (feature 1 <= 35.0)\n",
      "            Predict: 0.0\n",
      "           Else (feature 1 > 35.0)\n",
      "            Predict: 0.0\n",
      "        Else (feature 1 > 39.0)\n",
      "         Predict: 0.0\n",
      "       Else (feature 1 > 44.0)\n",
      "        Predict: 1.0\n",
      "      Else (feature 1 > 45.0)\n",
      "       Predict: 0.0\n",
      "    Else (feature 1 > 60.0)\n",
      "     Predict: 1.0\n",
      "  Else (feature 0 > 0.0)\n",
      "   If (feature 1 <= 20.0)\n",
      "    If (feature 1 <= 13.0)\n",
      "     If (feature 0 <= 1.0)\n",
      "      If (feature 1 <= 2.0)\n",
      "       Predict: 0.0\n",
      "      Else (feature 1 > 2.0)\n",
      "       Predict: 1.0\n",
      "     Else (feature 0 > 1.0)\n",
      "      Predict: 1.0\n",
      "    Else (feature 1 > 13.0)\n",
      "     If (feature 0 <= 1.0)\n",
      "      If (feature 1 <= 17.0)\n",
      "       Predict: 1.0\n",
      "      Else (feature 1 > 17.0)\n",
      "       If (feature 1 <= 19.0)\n",
      "        If (feature 1 <= 18.0)\n",
      "         Predict: 1.0\n",
      "        Else (feature 1 > 18.0)\n",
      "         Predict: 1.0\n",
      "       Else (feature 1 > 19.0)\n",
      "        Predict: 1.0\n",
      "     Else (feature 0 > 1.0)\n",
      "      If (feature 1 <= 18.0)\n",
      "       If (feature 1 <= 17.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 1 > 17.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 1 > 18.0)\n",
      "       If (feature 1 <= 19.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 1 > 19.0)\n",
      "        Predict: 1.0\n",
      "   Else (feature 1 > 20.0)\n",
      "    If (feature 0 <= 1.0)\n",
      "     If (feature 1 <= 60.0)\n",
      "      If (feature 1 <= 47.0)\n",
      "       If (feature 1 <= 28.0)\n",
      "        If (feature 1 <= 25.0)\n",
      "         If (feature 1 <= 23.0)\n",
      "          If (feature 1 <= 22.0)\n",
      "           Predict: 1.0\n",
      "          Else (feature 1 > 22.0)\n",
      "           Predict: 1.0\n",
      "         Else (feature 1 > 23.0)\n",
      "          If (feature 1 <= 24.0)\n",
      "           Predict: 0.0\n",
      "          Else (feature 1 > 24.0)\n",
      "           Predict: 0.0\n",
      "        Else (feature 1 > 25.0)\n",
      "         If (feature 1 <= 27.0)\n",
      "          Predict: 1.0\n",
      "         Else (feature 1 > 27.0)\n",
      "          Predict: 1.0\n",
      "       Else (feature 1 > 28.0)\n",
      "        If (feature 1 <= 30.0)\n",
      "         Predict: 0.0\n",
      "        Else (feature 1 > 30.0)\n",
      "         If (feature 1 <= 45.0)\n",
      "          If (feature 1 <= 32.0)\n",
      "           Predict: 1.0\n",
      "          Else (feature 1 > 32.0)\n",
      "           If (feature 1 <= 36.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 1 > 36.0)\n",
      "            Predict: 0.0\n",
      "         Else (feature 1 > 45.0)\n",
      "          Predict: 0.0\n",
      "      Else (feature 1 > 47.0)\n",
      "       If (feature 1 <= 54.0)\n",
      "        If (feature 1 <= 50.0)\n",
      "         Predict: 1.0\n",
      "        Else (feature 1 > 50.0)\n",
      "         Predict: 1.0\n",
      "       Else (feature 1 > 54.0)\n",
      "        Predict: 1.0\n",
      "     Else (feature 1 > 60.0)\n",
      "      Predict: 0.0\n",
      "    Else (feature 0 > 1.0)\n",
      "     If (feature 1 <= 54.0)\n",
      "      If (feature 1 <= 23.0)\n",
      "       If (feature 1 <= 21.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 1 > 21.0)\n",
      "        If (feature 1 <= 22.0)\n",
      "         Predict: 0.0\n",
      "        Else (feature 1 > 22.0)\n",
      "         Predict: 0.0\n",
      "      Else (feature 1 > 23.0)\n",
      "       If (feature 1 <= 24.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 1 > 24.0)\n",
      "        If (feature 1 <= 27.0)\n",
      "         If (feature 1 <= 26.0)\n",
      "          If (feature 1 <= 25.0)\n",
      "           Predict: 0.0\n",
      "          Else (feature 1 > 25.0)\n",
      "           Predict: 0.0\n",
      "         Else (feature 1 > 26.0)\n",
      "          Predict: 0.0\n",
      "        Else (feature 1 > 27.0)\n",
      "         If (feature 1 <= 28.0)\n",
      "          Predict: 1.0\n",
      "         Else (feature 1 > 28.0)\n",
      "          If (feature 1 <= 30.0)\n",
      "           If (feature 1 <= 29.0)\n",
      "            Predict: 0.0\n",
      "           Else (feature 1 > 29.0)\n",
      "            Predict: 0.0\n",
      "          Else (feature 1 > 30.0)\n",
      "           If (feature 1 <= 32.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 1 > 32.0)\n",
      "            Predict: 0.0\n",
      "     Else (feature 1 > 54.0)\n",
      "      Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate decision tree model on training instances \n",
    "predictions = model.predict(trainingData.map(lambda x: x.features))\n",
    "labelsAndPredictions = trainingData.map(lambda lp: lp.label).zip(predictions)\n",
    "trainErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(trainingData.count())\n",
    "trainAcc = labelsAndPredictions.filter(lambda (v, p): v == p).count() / float(trainingData.count())\n",
    "print('Training Error = ' + str(trainErr))\n",
    "print('Training Accuracy = ' + str(trainAcc))\n",
    "print('Learned classification random forest model:')\n",
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.376\n",
      "Test Accuracy = 0.624\n"
     ]
    }
   ],
   "source": [
    "# Evaluate decision tree model on test instances \n",
    "predictions = model.predict(testData.map(lambda x: x.features))\n",
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(testData.count())\n",
    "testAcc = labelsAndPredictions.filter(lambda (v, p): v == p).count() / float(testData.count())\n",
    "print('Test Error = ' + str(testErr))\n",
    "print('Test Accuracy = ' + str(testAcc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import RandomForest\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "# Train a RandomForest model.\n",
    "#  Empty categoricalFeaturesInfo indicates all features are continuous.\n",
    "#  Note: Use larger numTrees in practice.\n",
    "#  Setting featureSubsetStrategy=\"auto\" lets the algorithm choose.\n",
    "model2 = RandomForest.trainClassifier(trainingData, numClasses=2, categoricalFeaturesInfo={},numTrees=8000, featureSubsetStrategy='all',impurity='gini', maxDepth=25, maxBins=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Get accuracy measures for random forest model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error = 0.292490118577\n",
      "Training Accuracy = 0.707509881423\n",
      "Learned classification random forest model:\n"
     ]
    }
   ],
   "source": [
    "# Evaluate random forest model on training instances and compute test error\n",
    "predictions2 = model2.predict(trainingData.map(lambda x: x.features))\n",
    "labelsAndPredictions2 = trainingData.map(lambda lp: lp.label).zip(predictions2)\n",
    "trainErr2 = labelsAndPredictions2.filter(lambda (v, p): v != p).count() / float(trainingData.count())\n",
    "trainAcc2 = labelsAndPredictions2.filter(lambda (v, p): v == p).count() / float(trainingData.count())\n",
    "print('Training Error = ' + str(trainErr2))\n",
    "print('Training Accuracy = ' + str(trainAcc2))\n",
    "print('Learned classification random forest model:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.348\n",
      "Test Accuracy = 0.652\n"
     ]
    }
   ],
   "source": [
    "# Evaluate random forest model on test instances \n",
    "predictions = model2.predict(testData.map(lambda x: x.features))\n",
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr2 = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(testData.count())\n",
    "testAcc2 = labelsAndPredictions.filter(lambda (v, p): v == p).count() / float(testData.count())\n",
    "print('Test Error = ' + str(testErr2))\n",
    "print('Test Accuracy = ' + str(testAcc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Trees Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build the gradient boosting model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "# Train a GradientBoostedTrees model.\n",
    "model3 = GradientBoostedTrees.trainClassifier(trainingData,categoricalFeaturesInfo={}, numIterations=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate perforamance of gradient boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error = 0.243083003953\n",
      "Training Accuracy = 0.756916996047\n"
     ]
    }
   ],
   "source": [
    "# Evaluate gradient boosting on training instances and compute test error\n",
    "predictions3 = model3.predict(trainingData.map(lambda x: x.features))\n",
    "labelsAndPredictions3 = trainingData.map(lambda lp: lp.label).zip(predictions3)\n",
    "trainErr3 = labelsAndPredictions3.filter(lambda (v, p): v != p).count() / float(trainingData.count())\n",
    "trainAcc3 = labelsAndPredictions3.filter(lambda (v, p): v == p).count() / float(trainingData.count())\n",
    "print('Training Error = ' + str(trainErr3))\n",
    "print('Training Accuracy = ' + str(trainAcc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.356\n",
      "Test Accuracy = 0.644\n"
     ]
    }
   ],
   "source": [
    "# Evaluate gradient boosting model on test instances \n",
    "predictions = model3.predict(testData.map(lambda x: x.features))\n",
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr3 = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(testData.count())\n",
    "testAcc3 = labelsAndPredictions.filter(lambda (v, p): v == p).count() / float(testData.count())\n",
    "print('Test Error = ' + str(testErr3))\n",
    "print('Test Accuracy = ' + str(testAcc3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "model5 = SVMWithSGD.train(trainingData, iterations=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error = 0.381422924901\n",
      "Training Accuracy = 0.618577075099\n"
     ]
    }
   ],
   "source": [
    "# Evaluate svm model on training instances\n",
    "predictions5 = model5.predict(trainingData.map(lambda x: x.features))\n",
    "labelsAndPredictions5 = trainingData.map(lambda lp: lp.label).zip(predictions5)\n",
    "trainErr5 = labelsAndPredictions5.filter(lambda (v, p): v != p).count() / float(trainingData.count())\n",
    "trainAcc5 = labelsAndPredictions5.filter(lambda (v, p): v == p).count() / float(trainingData.count())\n",
    "print('Training Error = ' + str(trainErr5))\n",
    "print('Training Accuracy = ' + str(trainAcc5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.416\n",
      "Test Accuracy = 0.584\n"
     ]
    }
   ],
   "source": [
    "# Evaluate svm model on test instances \n",
    "predictions = model5.predict(testData.map(lambda x: x.features))\n",
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr5 = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(testData.count())\n",
    "testAcc5 = labelsAndPredictions.filter(lambda (v, p): v == p).count() / float(testData.count())\n",
    "print('Test Error = ' + str(testErr5))\n",
    "print('Test Accuracy = ' + str(testAcc5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Model Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Training = 0.752964426877 Test = 0.624\n",
      "Random Forest: Training = 0.707509881423 Test = 0.652\n",
      "Gradient Boost: Training = 0.756916996047 Test = 0.644\n",
      "Support Vector: Training = 0.618577075099 Test = 0.584\n"
     ]
    }
   ],
   "source": [
    "# Compare Results of all models\n",
    "print('Decision Tree: Training = ' + str(trainAcc) + ' Test = '+ str(testAcc))\n",
    "print('Random Forest: Training = ' + str(trainAcc2) + ' Test = '+ str(testAcc2))\n",
    "print('Gradient Boost: Training = ' + str(trainAcc3) + ' Test = '+ str(testAcc3))\n",
    "print('Support Vector: Training = ' + str(trainAcc5) + ' Test = '+ str(testAcc5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.0",
   "language": "python",
   "name": "python2-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
